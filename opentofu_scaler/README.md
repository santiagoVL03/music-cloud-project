# Infraestructura Kubernetes en AWS con OpenTofu/Terraform

Este proyecto despliega autom√°ticamente un cluster de Kubernetes (1 master + 2 workers) en AWS utilizando Infraestructura como C√≥digo (IaC) con OpenTofu/Terraform.

## üìã Caracter√≠sticas

- **Cluster Kubernetes**: 1 nodo master + 2 nodos worker
- **CNI**: Flannel con red de pods 10.244.0.0/16
- **Metrics Server**: Para HPA y monitoreo
- **HPA**: Horizontal Pod Autoscaler configurado para la aplicaci√≥n web
- **Despliegue autom√°tico**: PostgreSQL, aplicaci√≥n web y configuraci√≥n inicial
- **Gesti√≥n de tokens**: Uso de S3 para compartir tokens de join entre nodos

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      VPC 10.0.0.0/16                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ         Subnet Public A (10.0.1.0/24)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  K8s Master  ‚îÇ  ‚îÇ K8s Worker 1 ‚îÇ ‚îÇK8s Worker 2‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (t3.medium) ‚îÇ  ‚îÇ  (t3.small)  ‚îÇ ‚îÇ (t3.small) ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Flannel CNI | Metrics Server | HPA                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         Internet Gateway
```

## üîß Requisitos Previos

1. **OpenTofu o Terraform** instalado (versi√≥n >= 1.0)
2. **AWS CLI** configurado con credenciales v√°lidas
3. **Par de llaves SSH** para acceso a las instancias
4. **Permisos AWS** para crear VPC, EC2, S3, IAM roles

## üöÄ Despliegue

### Paso 1: Generar par de llaves SSH (si no tienes una)

```bash
ssh-keygen -t rsa -b 4096 -f ~/.ssh/k8s-cluster-key -N ""
```

### Paso 2: Configurar variables

Crea un archivo `terraform.tfvars`:

```hcl
aws_region            = "us-east-1"
ami_id                = "ami-0866a3c8686eaeeba"  # Ubuntu 24.04 LTS en us-east-1
master_instance_type  = "t3.medium"
worker_instance_type  = "t3.small"
worker_count          = 2
ssh_public_key        = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDa..."  # Tu clave p√∫blica
ssh_private_key_path  = "~/.ssh/k8s-cluster-key"  # Ruta a tu clave privada
```

**Nota**: Para obtener tu clave p√∫blica:
```bash
cat ~/.ssh/k8s-cluster-key.pub
```

### Paso 3: Inicializar Terraform/OpenTofu

```bash
cd opentofu_scaler
terraform init
# o
tofu init
```

### Paso 4: Planificar el despliegue

```bash
terraform plan
# o
tofu plan
```

### Paso 5: Aplicar la configuraci√≥n

```bash
terraform apply
# o
tofu apply
```

El proceso tomar√° aproximadamente **10-15 minutos**.

## üìä Verificaci√≥n del Cluster

### Conectarse al nodo master

```bash
# Obtener la IP del master desde los outputs
terraform output k8s_master_public_ip

# Conectarse via SSH
ssh -i ~/.ssh/k8s-cluster-key ubuntu@<MASTER_IP>
```

### Verificar los nodos

```bash
kubectl get nodes
```

Deber√≠as ver algo como:
```
NAME         STATUS   ROLES           AGE   VERSION
k8s-master   Ready    control-plane   10m   v1.28.x
k8s-worker-1 Ready    <none>          8m    v1.28.x
k8s-worker-2 Ready    <none>          8m    v1.28.x
```

### Verificar los pods

```bash
kubectl get pods -A
```

### Verificar el HPA

```bash
kubectl get hpa
kubectl describe hpa web-hpa
```

## üåê Acceder a la Aplicaci√≥n

La aplicaci√≥n web est√° expuesta en el **NodePort 30080**:

```bash
# Obtener la URL desde los outputs
terraform output application_url

# Acceder desde el navegador
http://<MASTER_IP>:30080
```

## üìà Probar el Autoscaling

### Generar carga en la aplicaci√≥n

Desde el master, ejecuta:

```bash
# Instalar hey para pruebas de carga
wget https://hey-release.s3.us-east-2.amazonaws.com/hey_linux_amd64
chmod +x hey_linux_amd64
sudo mv hey_linux_amd64 /usr/local/bin/hey

# Generar carga (ajusta la IP del servicio)
hey -z 5m -c 50 http://<SERVICE_IP>:8000
```

### Monitorear el escalado

En otra terminal SSH:

```bash
# Observar el HPA en tiempo real
watch kubectl get hpa

# Ver los pods escalando
watch kubectl get pods

# Ver m√©tricas
kubectl top nodes
kubectl top pods
```

## üîç Debugging

### Sistema de Logs Mejorado

Cada nodo genera m√∫ltiples archivos de log organizados en `/var/log/k8s-setup/`:

**En el Master:**
- `/var/log/k8s-setup/master-complete.log` - Log completo con toda la salida
- `/var/log/k8s-setup/master-errors.log` - Solo errores
- `/var/log/k8s-setup/master-init.log` - Log principal con timestamps
- `/home/ubuntu/setup-summary.txt` - Resumen de instalaci√≥n

**En los Workers:**
- `/var/log/k8s-setup/worker-complete.log` - Log completo con toda la salida
- `/var/log/k8s-setup/worker-errors.log` - Solo errores
- `/var/log/k8s-setup/worker-init.log` - Log principal con timestamps
- `/home/ubuntu/setup-summary.txt` - Resumen de instalaci√≥n

### Visor de Logs Interactivo

Usa el script `view-logs.sh` para ver los logs f√°cilmente:

```bash
./view-logs.sh
```

Este script te permite:
1. Ver logs completos del master
2. Ver solo errores del master
3. Ver resumen de instalaci√≥n del master
4. Ver logs de workers
5. Ver solo errores de workers
6. Ver resumen de workers
7. **Descargar TODOS los logs localmente**
8. Ver logs en tiempo real (tail -f)

### Ver logs manualmente del master

```bash
# Conectarse al master
ssh -i ~/.ssh/k8s-cluster-key ubuntu@<MASTER_IP>

# Ver log completo
sudo cat /var/log/k8s-setup/master-complete.log

# Ver solo errores
sudo cat /var/log/k8s-setup/master-errors.log

# Ver log en tiempo real
sudo tail -f /var/log/k8s-setup/master-complete.log

# Ver resumen
cat ~/setup-summary.txt
```

### Ver logs de un worker

```bash
# Conectarse al worker
ssh -i ~/.ssh/k8s-cluster-key ubuntu@<WORKER_IP>

# Ver log completo
sudo cat /var/log/k8s-setup/worker-complete.log

# Ver solo errores
sudo cat /var/log/k8s-setup/worker-errors.log

# Ver log en tiempo real
sudo tail -f /var/log/k8s-setup/worker-complete.log

# Ver resumen
cat ~/setup-summary.txt
```

### Descargar logs localmente

```bash
# Usar el script autom√°tico
./view-logs.sh
# Selecciona opci√≥n 7

# O manualmente
scp -i ~/.ssh/k8s-cluster-key ubuntu@<MASTER_IP>:/var/log/k8s-setup/*.log ./
```

### Ver logs de un pod

```bash
kubectl logs <pod-name>
kubectl logs -f deployment/web
kubectl logs -f deployment/postgres
```

### Ver eventos del cluster

```bash
kubectl get events --sort-by='.lastTimestamp'
```

## üßπ Limpieza

Para destruir toda la infraestructura:

```bash
terraform destroy
# o
tofu destroy
```

**IMPORTANTE**: Esto eliminar√° todas las instancias EC2, el bucket S3, VPC y recursos asociados.

## üìù Componentes Desplegados

### Infraestructura AWS
- ‚úÖ VPC con CIDR 10.0.0.0/16
- ‚úÖ Subnet p√∫blica en availability zone A
- ‚úÖ Internet Gateway y tablas de ruteo
- ‚úÖ Security Group para cluster K8s
- ‚úÖ 1 instancia EC2 t3.medium (master)
- ‚úÖ 2 instancias EC2 t3.small (workers)
- ‚úÖ Bucket S3 para tokens de join
- ‚úÖ IAM roles y policies

### Kubernetes
- ‚úÖ Cluster K8s v1.28
- ‚úÖ Flannel CNI (10.244.0.0/16)
- ‚úÖ Metrics Server con TLS insecure
- ‚úÖ Deployment PostgreSQL
- ‚úÖ Deployment Web (musiccloud)
- ‚úÖ Job de inicializaci√≥n de BD
- ‚úÖ HPA configurado (1-5 replicas, 50% CPU)
- ‚úÖ Services (ClusterIP para Postgres, NodePort para Web)

## üõ†Ô∏è Personalizaci√≥n

### Cambiar n√∫mero de workers

En `terraform.tfvars`:
```hcl
worker_count = 3  # Cambia a 3 o m√°s workers
```

### Cambiar tipos de instancia

```hcl
master_instance_type = "t3.large"
worker_instance_type = "t3.medium"
```

### Cambiar regi√≥n de AWS

```hcl
aws_region = "us-west-2"
ami_id     = "ami-xxx"  # AMI de Ubuntu en esa regi√≥n
```

Para encontrar AMIs de Ubuntu: https://cloud-images.ubuntu.com/locator/ec2/

## üîê Seguridad

‚ö†Ô∏è **Consideraciones de seguridad**:

1. El Security Group permite SSH (22) desde 0.0.0.0/0 - **Restringir a tu IP en producci√≥n**
2. El API Server (6443) est√° expuesto - **Considerar VPN o bastion host**
3. Las claves SSH deben protegerse adecuadamente
4. El bucket S3 contiene tokens sensibles - **Se elimina autom√°ticamente al destruir**

### Restringir acceso SSH solo a tu IP

En `main.tf`, modifica el security group:

```hcl
ingress {
  from_port   = 22
  to_port     = 22
  protocol    = "tcp"
  cidr_blocks = ["TU_IP/32"]  # Reemplaza con tu IP
  description = "SSH access"
}
```

## üìö Referencias

- [Kubernetes Official Documentation](https://kubernetes.io/docs/)
- [kubeadm Setup](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/)
- [Flannel CNI](https://github.com/flannel-io/flannel)
- [Metrics Server](https://github.com/kubernetes-sigs/metrics-server)
- [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

## üìÑ Licencia

Este proyecto es para fines educativos.

## üë§ Autor

Santiago - Music Cloud Project

---

**Nota**: Este cluster est√° optimizado para desarrollo y pruebas. Para producci√≥n, considera usar servicios administrados como EKS, AKS o GKE.
